
import { GoogleGenAI } from "@google/genai";
import { Sale } from '../types';

// Fun√ß√£o robusta para obter a API Key em diferentes ambientes (Vite, Process, etc)
const getApiKey = (): string => {
  try {
    // Tentativa 1: Padr√£o Vite (mais prov√°vel para este projeto)
    // @ts-ignore
    if (typeof import.meta !== 'undefined' && import.meta.env && import.meta.env.VITE_API_KEY) {
      // @ts-ignore
      return import.meta.env.VITE_API_KEY;
    }
  } catch (e) { console.debug('Vite env not found'); }

  try {
    // Tentativa 2: Padr√£o Node/Webpack (process.env)
    if (typeof process !== 'undefined' && process.env) {
      return process.env.VITE_API_KEY || process.env.API_KEY || '';
    }
  } catch (e) { console.debug('Process env not found'); }

  return '';
};

const API_KEY = getApiKey();

// Configura√ß√£o para LLM Local (LM Studio / Ollama)
const LOCAL_LLM_CONFIG = {
  enabled: false, // Pode ser alterado via localStorage ou UI
  baseUrl: 'http://127.0.0.1:1234/v1', // Padr√£o LM Studio (conforme seu acesso)
  model: 'google/gemma-3n-e4b' // Nome do modelo no LM Studio
};

// Fun√ß√£o para verificar se deve usar LLM Local
const shouldByPassGemini = () => {
  const saved = localStorage.getItem('AIR_SALES_LLM_CONFIG');
  if (saved) {
    try {
      const config = JSON.parse(saved);
      return config.useLocal;
    } catch (e) { return false; }
  }
  return LOCAL_LLM_CONFIG.enabled;
};

const getLocalConfig = () => {
  const saved = localStorage.getItem('AIR_SALES_LLM_CONFIG');
  if (saved) {
    try {
      return JSON.parse(saved);
    } catch (e) { return LOCAL_LLM_CONFIG; }
  }
  return LOCAL_LLM_CONFIG;
};

// Inicializa o cliente Gemini
// Se a chave n√£o existir, passamos uma string vazia para n√£o quebrar a inicializa√ß√£o, 
// mas validamos antes de chamar os m√©todos.
const ai = new GoogleGenAI({ apiKey: API_KEY || 'MISSING_KEY' });

const parseValue = (val: any) => {
  if (typeof val === 'number') return val;
  if (!val) return 0;
  return parseFloat(String(val).replace(/\./g, '').replace(',', '.'));
};

const formatCurrency = (val: number) => {
  return new Intl.NumberFormat('pt-BR', { style: 'currency', currency: 'BRL' }).format(val);
};

// Fun√ß√£o auxiliar para gerar o contexto de dados (reutiliz√°vel)
const buildDataContext = (salesData: Sale[], metrics: any) => {
    if (salesData.length === 0) return "N√£o h√° dados dispon√≠veis no filtro atual.";

    const totalVendas = salesData.reduce((acc, curr) => acc + parseValue(curr.ITP_RE_VALORMERCADORIA), 0);
    const ticketMedio = totalVendas / salesData.length;

    // Top Clientes
    const clientesMap = new Map<string, number>();
    salesData.forEach(s => {
      const nome = s.CLIENTE_NOME || 'DESCONHECIDO';
      const val = parseValue(s.ITP_RE_VALORMERCADORIA);
      clientesMap.set(nome, (clientesMap.get(nome) || 0) + val);
    });
    const topClientes = Array.from(clientesMap.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 15) 
      .map(([nome, val]) => `${nome} (${formatCurrency(val)})`)
      .join(', ');

    // Top Produtos (AGORA COM C√ìDIGO)
    const produtosMap = new Map<string, number>();
    salesData.forEach(s => {
      const codigo = s.PRO_ST_ALTERNATIVO || s.PRO_IN_CODIGO || '?';
      const desc = s.ITP_ST_DESCRICAO || 'ITEM';
      // Cria uma chave composta para garantir que a IA veja o c√≥digo
      const label = `[C√≥d: ${codigo}] ${desc}`;
      
      const val = parseValue(s.ITP_RE_VALORMERCADORIA);
      produtosMap.set(label, (produtosMap.get(label) || 0) + val);
    });
    
    const topProdutos = Array.from(produtosMap.entries())
      .sort((a, b) => b[1] - a[1])
      .slice(0, 15) // Aumentei para 15 para dar mais contexto
      .map(([nome, val]) => `${nome} - Total: ${formatCurrency(val)}`)
      .join('\n'); // Usando quebra de linha para ficar mais claro para a IA

    // Status
    const statusMap = new Map<string, number>();
    salesData.forEach(s => {
      const st = s.PED_ST_STATUS || 'OUTROS';
      statusMap.set(st, (statusMap.get(st) || 0) + 1);
    });
    const statusDist = Array.from(statusMap.entries())
      .map(([st, count]) => `${st}: ${count}`)
      .join(', ');

    return `
      DADOS ATUAIS (FILTRADOS NA TELA):
      - Total Geral Vendas: ${formatCurrency(totalVendas)}
      - Meta do Per√≠odo: ${formatCurrency(metrics.goal || 0)}
      - Atingimento Meta: ${metrics.achievement?.toFixed(1)}%
      - Quantidade de Pedidos: ${salesData.length}
      - Ticket M√©dio: ${formatCurrency(ticketMedio)}
      
      TOP PRODUTOS (Mais Vendidos):
      ${topProdutos}
      
      TOP CLIENTES (Maiores Compradores):
      ${topClientes}
      
      DISTRIBUI√á√ÉO DE STATUS:
      ${statusDist}
    `;
};

export const generateSalesInsights = async (
  salesData: Sale[], 
  context: string,
  metrics: any
): Promise<string> => {
  const useLocal = shouldByPassGemini();
  const localConfig = getLocalConfig();

  if (!useLocal && !API_KEY) {
    return "‚ö†Ô∏è **Erro de Configura√ß√£o**: Chave de API n√£o encontrada.\n\nPor favor, adicione a vari√°vel `VITE_API_KEY` nas configura√ß√µes do Vercel com sua chave do Google Gemini.";
  }

  try {
    const dataContext = buildDataContext(salesData, metrics);
    
    const prompt = `
      Voc√™ √© um Especialista S√™nior em Intelig√™ncia de Vendas (Business Intelligence Analyst).
      Analise o seguinte resumo do m√≥dulo "${context}":
      
      ${dataContext}

      **Sua Miss√£o**:
      Forne√ßa uma an√°lise executiva, direta e estrat√©gica em Portugu√™s (Brasil).
      Use formata√ß√£o Markdown simples.
      
      Estrutura da resposta:
      1. üîç **Diagn√≥stico R√°pido**
      2. üèÜ **Destaques** (Quem carrega o resultado)
      3. ‚ö†Ô∏è **Pontos de Aten√ß√£o** (Riscos, gargalos)
      4. üöÄ **A√ß√£o Recomendada** (2 sugest√µes pr√°ticas)

      Seja conciso.
    `;

    if (useLocal) {
      const response = await fetch(`${localConfig.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: localConfig.model,
          messages: [{ role: 'user', content: prompt }],
          temperature: 0.4
        })
      });
      const json = await response.json();
      return json.choices[0].message.content || "Sem resposta do modelo local.";
    }

    const response = await ai.models.generateContent({
      model: 'gemini-3-flash-preview',
      contents: prompt,
      config: { temperature: 0.4 }
    });

    return response.text || "N√£o foi poss√≠vel gerar a an√°lise no momento.";

  } catch (error: any) {
    console.error("Erro na IA:", error);
    
    if (useLocal && (error.message?.includes('fetch') || error.name === 'TypeError' || error.message?.includes('NetworkError'))) {
      console.log("Tentando conectar em:", localConfig.baseUrl);
      return `‚ö†Ô∏è **Erro de Conex√£o Local**: N√£o foi poss√≠vel alcan√ßar o seu modelo em \`${localConfig.baseUrl}\`.
      
**Como resolver agora:**
1. Verifique se o IP no menu **Configura√ß√µes IA** √© o mesmo que aparece no seu LM Studio (ex: \`192.168.15.85\`).
2. No Chrome/Edge, clique no **Cadeado** ao lado da URL {'>'} **Configura√ß√µes do site** {'>'} **Conte√∫do Inseguro** {'>'} **Permitir**.
3. Recarregue a p√°gina e tente novamente.`;
    }

    if (error.message?.includes('API_KEY')) {
        return "Erro de autentica√ß√£o com a IA. Verifique se a chave API est√° correta.";
    }
    return `Ocorreu um erro ao comunicar com a Intelig√™ncia Artificial. (${error.message || 'Erro desconhecido'})`;
  }
};

export const chatWithSalesData = async (
  history: { role: 'user' | 'model', text: string }[],
  salesData: Sale[],
  metrics: any,
  lastMessage: string
): Promise<string> => {
  const useLocal = shouldByPassGemini();
  const localConfig = getLocalConfig();

  if (!useLocal && !API_KEY) {
    return "Erro: Chave de API (VITE_API_KEY) n√£o configurada no servidor.";
  }

  try {
    const dataContext = buildDataContext(salesData, metrics);

    if (useLocal) {
      console.log("Chat Local - Enviando para:", localConfig.baseUrl);
      const messages = [
        {
          role: 'user',
          content: `INSTRU√á√ÉO DE SISTEMA: Voc√™ √© o assistente virtual do Air Sales, um especialista em an√°lise de dados comerciais.
          CONTEXTO DE DADOS ATUALIZADO:
          ${dataContext}
          REGRAS:
          1. Responda APENAS com base nos dados fornecidos acima.
          2. Seja prestativo, profissional e use formata√ß√£o Markdown.
          3. Se o usu√°rio perguntar sobre c√≥digos de produtos, use a informa√ß√£o que est√° entre colchetes [C√≥d: ...].
          4. Mantenha as respostas curtas e objetivas.
          
          PERGUNTA DO USU√ÅRIO: ${lastMessage}`
        }
      ];

      // Se houver hist√≥rico, podemos tentar enviar, mas para modelos locais simples, 
      // enviar o contexto + a √∫ltima mensagem em um √∫nico prompt de 'user' √© mais garantido.
      
      const response = await fetch(`${localConfig.baseUrl}/chat/completions`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          model: localConfig.model,
          messages,
          temperature: 0.7
        })
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Erro do Servidor Local (${response.status}): ${errorText}`);
      }

      const json = await response.json();
      return json.choices?.[0]?.message?.content || "Sem resposta do modelo local.";
    }

    const chatHistory = history.map(h => ({
        role: h.role,
        parts: [{ text: h.text }]
    }));

    const chatSession = ai.chats.create({
        model: 'gemini-3-flash-preview',
        history: chatHistory,
        config: {
            systemInstruction: `
              Voc√™ √© o assistente virtual do Air Sales, um especialista em an√°lise de dados comerciais.
              
              CONTEXTO DE DADOS ATUALIZADO:
              ${dataContext}
              
              REGRAS:
              1. Responda APENAS com base nos dados fornecidos acima.
              2. Seja prestativo, profissional e use formata√ß√£o Markdown.
              3. Se o usu√°rio perguntar sobre c√≥digos de produtos, use a informa√ß√£o que est√° entre colchetes [C√≥d: ...].
              4. Mantenha as respostas curtas e objetivas.
            `
        }
    });

    const result = await chatSession.sendMessage({ message: lastMessage });
    return result.text || "Sem resposta.";

  } catch (error: any) {
    console.error("Erro no Chat IA:", error);

    if (useLocal && (error.message?.includes('fetch') || error.name === 'TypeError' || error.message?.includes('NetworkError'))) {
      return "‚ö†Ô∏è **Erro de Conex√£o Local**: N√£o consegui falar com o seu PC. Verifique o IP nas configura√ß√µes e certifique-se de que permitiu 'Conte√∫do Inseguro' no cadeado do navegador.";
    }

    return "Desculpe, tive um problema ao processar sua pergunta. Tente novamente.";
  }
};
